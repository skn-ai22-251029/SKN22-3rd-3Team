from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage
from langgraph.types import Command
from .state import AgentState
from src.core.prompts.prompt_manager import prompt_manager
from src.retrieval.hybrid_search import HybridRetriever
from src.core.models.user_profile import UserProfile
from src.core.models.matchmaker import BreedSelection, SearchIntent

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

async def matchmaker_node(state: AgentState) -> Command:
    """
    ë§¤ì¹˜ë©”ì´ì»¤: ê³ ì–‘ì´ í’ˆì¢… ì¶”ì²œ ì „ë¬¸ê°€.
    1. ê²€ìƒ‰ ì˜ë„ ë¶„ë¥˜ (LOOKUP vs RECOMMEND)
    2. ë™ì  ì¿¼ë¦¬ ìƒì„± ë° ê²€ìƒ‰
    3. ì—ì´ì „í‹± ì„ ë³„ (Top 3)
    """
    query = state["messages"][-1].content
    
    # UserProfile ì´ˆê¸°í™”
    profile_data = state.get("user_profile", {})
    if isinstance(profile_data, dict):
        profile = UserProfile.from_dict(profile_data)
    else:
        profile = profile_data
        
    context = profile.to_context_string()
    persona = prompt_manager.get_prompt("matchmaker", field="persona")

    # 1. ê²€ìƒ‰ ì˜ë„ ë¶„ë¥˜ (Intent Classification)
    intent_classifier = llm.with_structured_output(SearchIntent)
    intent = await intent_classifier.ainvoke([
        SystemMessage(content=(
            "ë‹¹ì‹ ì€ ê³ ì–‘ì´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ ì˜ë„ë¥¼ ë¶„ë¥˜í•˜ì„¸ìš”.\n"
            "- LOOKUP: íŠ¹ì • í’ˆì¢…ì— ëŒ€í•œ ì •ë³´ë‚˜ íŠ¹ì§•ì„ ë¬»ëŠ” ê²½ìš° (í”„ë¡œí•„ ë¬´ì‹œ)\n"
            "- RECOMMEND: ì¶”ì²œì„ ìš”ì²­í•˜ëŠ” ê²½ìš° (ì‚¬ìš©ì í™˜ê²½ í”„ë¡œí•„ ë°˜ì˜ í•„ìš”)"
        )),
        SystemMessage(content=query)
    ], config={"tags": ["router_classification"]})

    # 2. ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
    if intent.category == "RECOMMEND":
        # ì¶”ì²œ: í”„ë¡œí•„ ì ê·¹ ë°˜ì˜
        search_query = f"{intent.keywords} (ì§‘ì‚¬ í™˜ê²½: {context})"
        specialist_mode = "Matchmaker (Recommendation)"
    else:
        # ë‹¨ìˆœ ì¡°íšŒ: í”„ë¡œí•„ ë°°ì œ
        search_query = intent.keywords
        specialist_mode = "Matchmaker (Lookup)"
        
    print(f"ğŸ•µï¸ [MATCHMAKER] Intent: {intent.category}, Query: {search_query}")

    # 3. 10ê±´ í›„ë³´ ê²€ìƒ‰
    retriever = HybridRetriever(version="v3", collection_name="care_guides")
    raw_results = await retriever.search(
        search_query, 
        specialist="Matchmaker", # í•„í„°ë§ìš© ë©”íƒ€ë°ì´í„° íƒœê·¸
        filters={"categories": "Breeds"}, 
        limit=10
    )

    if not raw_results:
        return Command(update={"specialist_result": {"source": "matchmaker", "rag_docs": []}}, goto="head_butler")

    # 4. ì—ì´ì „í‹± ë­í‚¹: LLMì´ 10ê±´ ì¤‘ ìµœì  3ê±´ ì„ ë³„
    selection_prompt = f"""ë‹¹ì‹ ì€ ê³ ì–‘ì´ ì „ë¬¸ ë§¤ì¹˜ë©”ì´ì»¤ì…ë‹ˆë‹¤. 
ì•„ë˜ì˜ [ì‚¬ìš©ì í™˜ê²½]ê³¼ [ì§ˆë¬¸]ì„ ë°”íƒ•ìœ¼ë¡œ, 10ê°œì˜ [í›„ë³´ ë¦¬ìŠ¤íŠ¸] ì¤‘ì—ì„œ ê°€ì¥ ì í•©í•œ 3ë§ˆë¦¬ë¥¼ ì„ ì •í•˜ì„¸ìš”.

[ì‚¬ìš©ì í™˜ê²½]
{context if intent.category == "RECOMMEND" else "(ë‹¨ìˆœ ì¡°íšŒì´ë¯€ë¡œ í™˜ê²½ ë¬´ì‹œ)"}

[ì§ˆë¬¸]
{query}

[ì„ ì • ì›ì¹™]
1. ë‹¨ìˆœ ì¡°íšŒ(LOOKUP)ì¼ ê²½ìš° ì§ˆë¬¸í•œ í’ˆì¢…ì„ ìµœìš°ì„ ìœ¼ë¡œ ì°¾ìœ¼ì„¸ìš”.
2. ì¶”ì²œ(RECOMMEND)ì¼ ê²½ìš° ì•Œë ˆë¥´ê¸°/ê±°ì£¼í™˜ê²½ì„ ì—„ê²©íˆ ê³ ë ¤í•˜ì„¸ìš”.

[í›„ë³´ ë¦¬ìŠ¤íŠ¸]
"""
    for i, r in enumerate(raw_results):
        selection_prompt += f"{i}. {r.get('name_ko')} ({r.get('name_en')}): {r.get('summary')}\n"
        selection_prompt += f"   - íŠ¹ì§•: {', '.join(r.get('personality_traits', []))}\n"
        selection_prompt += f"   - í†µê³„: {r.get('stats', {})}\n\n"

    selector = llm.with_structured_output(BreedSelection)
    selection = await selector.ainvoke(
        [SystemMessage(content=selection_prompt)],
        config={"tags": ["router_classification"]}
    )
    
    # 5. ìƒìœ„ 3ê±´ í•„í„°ë§
    final_indices = selection.selected_indices[:3]
    top_results = [raw_results[i] for i in final_indices if i < len(raw_results)]

    # ì„ ë³„ëœ í’ˆì¢… ì •ë³´ë¥¼ ì§‘ì‚¬ìš©ìœ¼ë¡œ ì••ì¶•
    rag_context = ""
    if top_results:
        docs_block = "\n\n".join([
            f"[{r.get('name_ko', '')} ({r.get('name_en', '')})]\n{r.get('text', '')[:1500]}"
            for r in top_results
        ])
        distill_msg = await llm.ainvoke([
            SystemMessage(content=(
                "ì•„ë˜ ì¶”ì²œ í’ˆì¢… ì •ë³´ì—ì„œ ì‚¬ìš©ìì—ê²Œ ì„¤ëª…í•  í•µì‹¬ íŠ¹ì§•ë§Œ ê°„ê²°í•˜ê²Œ ì¶”ì¶œí•˜ì„¸ìš”.\n"
                "- í’ˆì¢…ë³„ 2~3ì¤„, ì„±ê²©/ìƒí™œí™˜ê²½ ì í•©ì„±/ì£¼ì˜ì‚¬í•­ ìœ„ì£¼\n"
                "- ì´ 400ì ì´ë‚´\n\n"
                f"[ì‚¬ìš©ì ì§ˆë¬¸]\n{query}\n\n"
                f"[ì¶”ì²œ í’ˆì¢… ì •ë³´]\n{docs_block}"
            ))
        ], config={"tags": ["router_classification"]})
        rag_context = distill_msg.content

    # UI DTO ê°€ê³µ
    results = []
    for r in top_results:
        clean_r = {k: (str(v) if k == "_id" else v) for k, v in r.items()}
        if "tags" not in clean_r:
            traits = clean_r.get("personality_traits", [])
            clean_r["tags"] = [f"#{t}" for t in traits[:4]] if traits else []
        results.append(clean_r)

    rag_docs = [
        {
            "title": r.get("name_ko", ""),
            "subtitle": r.get("name_en", ""),
            "source": "TheCatAPI, Wikipedia",
            "url": r.get("source_url") or r.get("source_urls", [""])[0] if r.get("source_urls") else "",
        }
        for r in raw_results
    ]

    reasoning_text = f"**[{intent.category}]** ëª¨ë“œë¡œ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤.\n\n[ì„ ë³„ ì´ìœ ]\n{selection.reasoning}"

    specialist_result = {
        "source": "matchmaker",
        "type": "breed_recommendation",
        "specialist_name": "ë§¤ì¹˜ë©”ì´ì»¤ ë¹„ì„œ",
        "persona": persona + f"\n\n{reasoning_text}",
        "user_context": context,
        "rag_context": rag_context,
        "rag_docs": rag_docs,
    }

    return Command(
        update={
            "specialist_result": specialist_result,
            "recommendations": results,
            "rag_docs": rag_docs,
        },
        goto="head_butler"
    )
