from typing import List, Dict, Any, Literal
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, AIMessage
from langgraph.types import Command
from .state import AgentState

llm = ChatOpenAI(model="gpt-4o-mini")

class AdoptionDecision(BaseModel):
    """ì…ì–‘ íŒ€ ë‚´ë¶€ ìƒì„¸ ë¶„ë¥˜ ëª¨ë¸"""
    category: Literal["matchmaker", "general"] = Field(description="ë¶„ë¥˜: ë§ì¶¤ í’ˆì¢… ì¶”ì²œ(matchmaker), ì¼ë°˜ ì…ì–‘ ì •ë³´(general)")
    reasoning: str = Field(description="ì´ ë¶„ë¥˜ë¥¼ ì„ íƒí•œ ë…¼ë¦¬ì  ì´ìœ ")

async def adoption_team_node(state: AgentState) -> Command:
    """
    Adoption Supervisor: Decides if the user needs a breed recommendation or general info.
    """
    system_prompt = """
    ë‹¹ì‹ ì€ ZIPSA ì„œë¹„ìŠ¤ì˜ 'Adoption Supervisor'ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬, **RAG ë°ì´í„°ë² ì´ìŠ¤ì˜ ì „ë¬¸ê°€ ë©”íƒ€ë°ì´í„°(specialists)**ì™€ ê°€ì¥ ì˜ ë§¤ì¹­ë˜ëŠ” í•˜ìœ„ ì „ë¬¸ê°€ì—ê²Œ ì•ˆë‚´í•˜ì„¸ìš”.

    [RAG ì „ë¬¸ê°€ ë§¤í•‘ ê¸°ì¤€]
    - matchmaker: **Matchmaker** (í’ˆì¢… ì¶”ì²œ) ë˜ëŠ” **Liaison** (ë³´í˜¸ì†Œ/ë²•ë¥ ) ì „ë¬¸ê°€ ì •ë³´ê°€ í•„ìš”í•œ ê²½ìš°.
    - general: íŠ¹ì • ì „ë¬¸ê°€ ì •ë³´ ì—†ì´ ì¼ë°˜ì ì¸ ì…ì–‘ ì ˆì°¨ë‚˜ ì¤€ë¹„ë¬¼ì— ëŒ€í•œ ì•ˆë‚´.

    [ì§€ì¹¨]
    - RAG ê²€ìƒ‰ì´ í•„ìš”í•˜ë©´ ë¬´ì¡°ê±´ 'matchmaker'ë¥¼ ì„ íƒí•˜ì„¸ìš”.
    - ëª¨í˜¸í•˜ë©´ 'general'ë¡œ ë¶„ë¥˜í•˜ë˜, 'ì¶”ì²œ', 'ë³´í˜¸ì†Œ' í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì „ë¬¸ê°€ì—ê²Œ ë„˜ê¸°ì„¸ìš”.
    """
    
    router = llm.with_structured_output(AdoptionDecision)
    decision = await router.ainvoke([SystemMessage(content=system_prompt)] + state["messages"])
    
    debug = state.get("debug_info", {})
    debug.update({
        "adoption_sub_specialist": decision.category,
        "adoption_reasoning": decision.reasoning
    })
    
    if decision.category == "matchmaker":
        return {"adoption_sub_specialist": "matchmaker", "debug_info": debug}
    else:
        msg = "ìƒˆë¡œìš´ ê°€ì¡±ì„ ë§ì´í•˜ëŠ” ê²ƒì€ í° ì¶•ë³µì…ë‹ˆë‹¤! ì…ì–‘ ì ˆì°¨ë‚˜ í•„ìˆ˜ ì¤€ë¹„ë¬¼ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹  ì ì´ ìˆë‹¤ë©´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”. í˜¹ì€ ì§‘ì‚¬ë‹˜ê»˜ ë”± ë§ëŠ” ê³ ì–‘ì´ë¥¼ ì¶”ì²œí•´ ë“œë¦´ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤."
        return {
            "adoption_sub_specialist": "general",
            "messages": [AIMessage(content=msg)],
            "debug_info": debug
        }

from src.retrieval.hybrid_search import HybridRetriever

async def matchmaker_node(state: AgentState) -> Command:
    """
    Expert node: Matchmaker (ë§ì¶¤ ì¶”ì²œ)
    Incorporates user profile into the search for better matching.
    """
    profile = state.get("user_profile", {})
    context = f"ê±°ì£¼í™˜ê²½: {profile.get('housing', '')}, í™œë™ëŸ‰: {profile.get('activity', '')}, ì„ í˜¸ì„±í–¥: {', '.join(profile.get('traits', []))}"
    
    retriever = HybridRetriever(collection_name="breeds")
    last_msg = state["messages"][-1].content
    search_query = f"{last_msg} (ì§‘ì‚¬ í™˜ê²½: {context})"
    
    results = await retriever.search(search_query, specialist="Matchmaker", limit=3)
    
    # Capture Debug Info
    debug = {
        "specialist": "Matchmaker",
        "search_query": search_query,
        "retrieved_docs": [
            {"title": r.get("name_ko", r.get("name", "Unknown")), "score": r.get("score", 0)} 
            for r in results
        ]
    }
    
    if results:
        top_breed = results[0]
        name_ko = top_breed.get("name_ko", top_breed.get("name", "ê³ ì–‘ì´"))
        summary = top_breed.get("summary_ko", "ìƒì„¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        recommendation_msg = f"ğŸ§© **[ì¸ì‚¬ë‹´ë‹¹ ë¹„ì„œ]** ì§‘ì‚¬ë‹˜ì˜ ë¼ì´í”„ìŠ¤íƒ€ì¼ì„ ë¶„ì„í•œ ê²°ê³¼, **{name_ko}** ì£¼ì¸ë‹˜ì´ ê°€ì¥ ì˜ ì–´ìš¸ë¦¬ì‹¤ ê²ƒ ê°™ìŠµë‹ˆë‹¤! \n\nğŸ©: `{summary}`"
        shelter_msg = f"\n\nğŸ”­ **[ëŒ€ì™¸í˜‘ë ¥ ë¹„ì„œ]** í˜„ì¬ í•´ë‹¹ {name_ko} ì£¼ì¸ë‹˜ê³¼ ì¸ì—°ì„ ë§ºì„ ìˆ˜ ìˆëŠ” ì¸ê·¼ ë³´í˜¸ì†Œ ì •ë³´ë¥¼ ì¡°íšŒ ì¤‘ì…ë‹ˆë‹¤. ì¡°ë§Œê°„ ê¸°ìœ ì†Œì‹ì„ ë“¤ë ¤ë“œë¦´ê²Œìš”!"
        
        return Command(
            update={
                "selected_breed": name_ko,
                "messages": [AIMessage(content=recommendation_msg + shelter_msg)],
                "debug_info": debug
            },
            goto="__end__"
        )
    
    return Command(
        update={
            "messages": [AIMessage(content="ğŸ§© ì£„ì†¡í•©ë‹ˆë‹¤. ì§‘ì‚¬ë‹˜ì˜ í™˜ê²½ì— ë”± ë§ëŠ” í’ˆì¢…ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¡°ê¸ˆ ë” êµ¬ì²´ì ì¸ ì„ í˜¸ë¥¼ ë§ì”€í•´ ì£¼ì‹œë©´ ë‹¤ì‹œ ì°¾ì•„ë³´ê² ìŠµë‹ˆë‹¤.")],
            "debug_info": debug
        },
        goto="__end__"
    )

async def liaison_node(state: AgentState) -> Command:
    """
    (Optional) Dedicated Liaison node if needed for complex search.
    Currently merged into matchmaker for consolidated UI output.
    """
    breed = state.get("selected_breed", "ê³ ì–‘ì´")
    shelter_msg = f"ğŸ”­ **[ëŒ€ì™¸í˜‘ë ¥ ë¹„ì„œ]** {breed} ì£¼ì¸ë‹˜ì„ ëª¨ì‹¤ ìˆ˜ ìˆëŠ” ë³´í˜¸ì†Œë¥¼ í™•ì¸ ì¤‘ì…ë‹ˆë‹¤..."
    return Command(update={"messages": [AIMessage(content=shelter_msg)]}, goto="__end__")
