# 개발 일지 (2026-01-28)

오늘 진행된 Phase 1(데이터 전처리) 및 Phase 2(아키텍처/인프라) 작업의 모든 상세 내용을 통합 기록합니다.

---

## 🚀 Phase 1: 데이터 수집 및 전처리 상세 (✅ 완료)

CatFit 프로젝트의 근간이 되는 지식 베이스와 품종 데이터 표준화 작업을 완수했습니다.

### 1. 지식 베이스 구축 (Bemypet Catlab)
- **데이터 소스**: 비마이펫(Bemypet) 고양이 연구소 아티클 **1,153개** 크롤링 완료.
- **LLM 전처리 (GPT-4o-mini)**: 단순 텍스트를 구조화된 메타데이터로 변환.
  - 카테고리화: 건강, 영양, 행동, 관리, 제품, 정보 등 6개 범주.
  - 검색 최적화: 아티클당 3~5개의 핵심 키워드 및 시맨틱 요약 생성.
  - 부가 정보: 사용자 예상 질문 및 주요 개체(Entity) 추출을 통한 RAG 품질 향상.
- **파이프라인 효율화**: `asyncio` 기반 병렬 처리 구조(`Pipeline`)를 도입하여 약 1,200개 문서를 **18분** 이내에 처리 (기존 동기 방식 대비 10배 이상 성능 개선).

### 2. 고양이 품종 백과사전 통합 (Integrated Breed Data)
- **데이터 소스**: TheCatAPI, Wikipedia, 마스터 CSV 데이터의 3자 병합.
- **국내화 (Localization)**: 영문 품종명을 국내 집사 커뮤니티 통용 명칭으로 정교하게 매칭 (**67개 품종**).
  - 예: *Aegean* -> 에게안 고양이, *Chartreux* -> 샤르트뢰, *Bengal* -> 벵갈.
- **특성 구조화**: 성격(Personality), 외형(Physical), 건강 스태츠(Stats)를 JSON으로 통합하여 추천 시스템의 토대 마련.

### 3. 전문가 데이터 표준화
- 유튜브 전문가 리포트(`youtube_extract.md`) 파싱 로직 구현.
- 아티클 데이터와 동일한 스키마로 표준화하여 지식 베이스 통합 완료.

---

## 🏗️ Phase 2: 아키텍처 리팩토링 및 인프라 구축 상세 (✅ 완료)

데이터 가공 이후 에이전트 시스템과 검색 엔진의 고도화를 진행했습니다.

### 1. 전면적인 프로젝트 구조 리팩토링
- **scripts/ 디렉토리 세분화**:
  - `crawl/`: Wikipedia, TheCatAPI 전용 크롤러.
  - `process/`: 데이터 통합, `ArticleClassifier`, `BreedClassifier` 등 처리 로직.
  - `validate/`: 데이터 유효성 및 무결성 검증.
  - `database/`: MongoDB 적재 및 인덱스 관리 (`ingest_to_mongodb.py`).
- **src/ 레이어링**: 
  - `embeddings/`: 임베딩 모델 추상화.
  - `agents/`: LangGraph 기반 독립된 팀/노드 로직.
  - `retrieval/`: 하이브리드 검색 구현.
  - `utils/`: `text.py` 크롤링 및 토큰화 공통 함수.

### 2. 모듈형 임베딩 시스템 (`src/embeddings/`)
- **Factory 패턴**: OpenAI(`text-embedding-3-small`)와 로컬 모델(`dragonkue/multilingual-e5-small-ko`) 동적 전환 모듈 구현.
- **런타임 안정성**: `sentence-transformers` 라이브러리의 M2 Mac MPS 충돌 문제를 피하기 위해 **Lazy Import** 적용.
- **Safe Ingestion**: MongoDB Atlas Vector Search 요구사항인 Float Array 변환, L2 Normalization, Dimension Validation 레이어 구축.

### 3. 계층형 LangGraph 1.0.7 시스템
- **Command 패턴 도입**: 최신 LangGraph 문법을 적용, `Conditional Edges` 대신 노드 내부에서 `Command(goto=...)`를 통한 선언적 라우팅 수행.
- **에이전트 페르소나**:
  - `Head Butler`: 인텐트 분류 및 전담 팀 배정.
  - `Adoption Team`: `Matchmaker`(RAG 품종 추천) → `Liaison`(보호소 자동 검색).
  - `Care Team`: `Physician`(건강/의료) + `Peacekeeper`(행동/사회성) 전문 노드.
- **RAG 통합**: 모든 전문가 노드가 `HybridRetriever`를 통해 실제 데이터에 근거한 실시간 조언 제공.

### 4. MongoDB Atlas 적재 및 M0 최적 인덱싱
- **적재 완료**: 품종 데이터 및 케어 가이드를 OpenAI 임베딩(1536 dim) 기반으로 업로드 완료.
- **인덱스 한도 최적화**: 무료 티어(M0)의 인덱스 제한(3개)을 고려한 구성.
  - `breeds`: Vector Search + Keyword Search(BM25).
  - `care_guides`: Vector Search 전용.
- **Field Name 수정**: 데이터 스키마 불일치 이슈 해결 (`name` -> `name_en`, `id` -> `breed_id`).

### 5. 지식 Taxonomy 및 페르소나 매칭 고도화 (Refinement)
- **문제 인식**: 단일 카테고리 분류의 한계(정보 손실)와 전문가 페르소나와의 연결성 부족 확인.
- **솔루션 (2-Layer Metadata)**:
    - **Layer 1 (Topic)**: 다중 라벨 카테고리 (건강, 영양, 행동, 생활, 법률, 이별 등).
    - **Layer 2 (Expert)**: 4대 전문가 페르소나(Matchmaker, Liaison, Peacekeeper, Physician) 태그 매핑.
- **기술적 구현**: 
    - `schemas.py`: `ArticleMetadata` 내 `categories`, `specialists` 리스트 필드 추가.
    - `article_classifier.py`: 전문가별 지식 영역을 정의하고 다중 추출을 수행하도록 프롬프트 고도화.
- **기대 효과**: 에이전트가 질문 의도에 따라 특정 전문가 영역의 데이터만 선별 검색(Pre-filtering) 가능, 검색 정확도 극대화.

---

## 🛠️ 기술 스택 및 라이브러리 목록
- **Backend / DB**: Python 3.12, Motor (Async MongoDB), Pymongo
- **Agent**: LangChain, LangGraph 1.0.7, OpenAI GPT-4o-mini
- **NLP**: Kiwipiepy (형태소 분석), Sentence-Transformers (Local E5-ko)
- **Infra**: MongoDB Atlas (Vector Search + Semantic Search)

## 🚀 향후 과제
- MongoDB Atlas 인덱스 활성화 및 검색 품질 정밀 튜닝.
- Streamlit 기반 유저 온보딩 폼과 에이전트 최종 연동.
- 로컬 임베딩 모델 가속성 재검토 및 최적 선택.

---
**CatFit Team** | "집사와 고양이의 더 나은 연결을 위한 기술적 여정"
**기록자**: CatFit AI Assistant 🎩
